+++
abstract = "Video quality assessment (VQA) remains an important and challenging problem that affects many applications at the widest scales. Recent advances in mobile devices and cloud computing techniques have made it possible to capture, process, and share high resolution, high frame rate (HFR) videos across the Internet nearly instantaneously. Being able to monitor and control the quality of these streamed videos can enable the delivery of more enjoyable content and perceptually optimized rate control. Accordingly, there is a pressing need to develop VQA models that can be deployed at enormous scales. While some recent effects have been applied to full-reference (FR) analysis of variable frame rate and HFR video quality, the development of no-reference (NR) VQA algorithms targeting frame rate variations has been little studied. Here, we propose a first-of-a-kind blind VQA model for evaluating HFR videos, which we dub the Framerate-Aware Video Evaluator w/o Reference (FAVER). FAVER uses extended models of spatial natural scene statistics that encompass space-time wavelet-decomposed video signals, to conduct efficient frame rate sensitive quality prediction. Our extensive experiments on several HFR video quality datasets show that FAVER outperforms other blind VQA algorithms at a reasonable computational cost."
abstract_short = " "
authors = ["Qi Zheng", "Zhengzhong Tu", "**Pavan C Madhusudana**", "Xiaoyang Zeng", "Alan C Bovik", "Yibo Fan"]
date = "2022-01-15"
image_preview = ""
math = true
publication_types = ["2"]
publication = "Preprint"
publication_short = "In *Preprint*"
selected = false
title = "FAVER: Blind Quality Prediction of Variable Frame Rate Videos"
url_code = "https://github.com/uniqzheng/HFR-BVQA"
url_dataset = ""
url_pdf = "https://arxiv.org/pdf/2201.01492"
url_project = ""
url_slides = ""
url_video = ""
url_poster = ""
url_preprint = ""
url_source = ""

# Optional featured image (relative to `static/img/` folder).
[header]
image = ""
caption = ""

+++



